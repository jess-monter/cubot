# ğŸ§  Cubot â€” Debate Chat API (LLM-powered)

Welcome to **Cubot**, a Django-based API for LLM-driven debate-style conversations. Built with Docker, using Ollama and a structured microservices approach.

---

## ğŸš€ Features

- Django REST API with structured conversation logic
- Integration with local Ollama LLM models (e.g., `phi3`)
- Fully containerized with Docker + Docker Compose
- Easily extensible `ChatEngine` and `DebateService` classes
- Includes Makefile commands for quick setup, test, and maintenance

---

## ğŸ“¦ Requirements

- Docker
- Docker Compose plugin

---

## ğŸ› ï¸ Installation

Run the following to install Docker and Docker Compose if not already present:

```bash
make install
```

âš ï¸ If the current user is not in the `docker` group, log out and back in, or run:

```bash
newgrp docker
```

---

## ğŸ§ª Running the Project

### Start the API and dependencies

```bash
make run
```

Visit the API at:  
```
http://localhost:3031
```

---

## ğŸ”Œ API Usage

### Endpoint: `POST api/chat/`

```json
{
  "conversation_id": "optional-uuid",
  "message": "Your message to the bot"
}
```

- If `conversation_id` is omitted, a new conversation is created.
- The response includes the updated conversation and latest messages.

---

## ğŸ§ª Running Tests

### Build and run the test suite:

```bash
make test
```

### Build only (useful for caching Docker layers):

```bash
make test-build
```

### Clean up test containers and volumes:

```bash
make test-clean
```

---

## âš™ï¸ Environment Variables

Configure your `.env` file at the root of the project:

```ini
SECRET_KEY=...
DEBUG=True

# Database
DB_HOST=localhost
DB_USER=postgres
DB_NAME=cubot_db
DB_PORT=5434
DB_PASSWORD=postgres

# Django
DJANGO_SETTINGS_MODULE=cubot.settings
ALLOWED_HOST=localhost

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=phi3
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ debate.py
â”‚   â”‚   â””â”€â”€ engines/
â”‚   â”‚       â”œâ”€â”€ base.py
â”‚   â”‚       â””â”€â”€ ollama_engine.py
â”œâ”€â”€ cubot/
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.test.yml
â”œâ”€â”€ entrypoint.sh
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

## ğŸ¤– Powered By

- [Django](https://www.djangoproject.com/)
- [Ollama](https://ollama.com/)
- [Docker](https://www.docker.com/)
- [pytest + pytest-django](https://pytest-django.readthedocs.io/)

---

## ğŸ§  Tips

- Use the `DebateService` and `ChatEngine` abstractions to plug in new LLMs or fine-tune logic.
- Run `make` to list all available commands.

---

